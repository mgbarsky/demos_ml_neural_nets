{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input is a set of feature vectors and the known answers for each vector - targets. Neural nets take input data that is observable, recordable, and by extension knowable and creates a logical model that can predict any future data.\n",
    "\n",
    "The neural network is simply a set of one or more weights which can be multiplied by the input vector to output a prediction or a class label. Thus, neural nets are good __both for the prediction and for the classification__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the prediction always correct? No, the network can make mistakes. But it can learn from its mistakes.<br>\n",
    "\n",
    "How does the network learn?<br>\n",
    "\n",
    "Trial and error! First, it tries to make a prediction. Then, it sees whether it was too high or too low. Finally, it changes the weight (up or down) to predict more\n",
    "accurately the next time it sees the same input. The algorithm consists of several iterations (*epochs) of **predict-compare-learn**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will demonstrate this idea with the simplest possible neural network which contains a single processing neuron. This self-learning network is called a *perceptron*. \n",
    "\n",
    "A feature vector is presented to this neuron. For each feature there is a weight, and the network predicts a target variable by multiplying each feature value by its weight and producing a weighted sum. \n",
    "\n",
    "For a simple case of binary classification, we will use an activation function *sign*: if the weighted sum is positive the neuron predicts class yes(1), and if the sum is negative it predicts no(0).\n",
    "\n",
    "<figure>\n",
    "    <img src=\"images/perceptron.png\" title=\"Simple Perceptron for 2D feature vector\" width=\"400px\">\n",
    "    <figcaption>Fig 1. Simple perceptron for classifying a vector of 2 features. Tranforms a weighted sum of features into a class using the <i>sign</i> function.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Implementation of a simple Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    \"\"\" Basic Perceptron\"\"\"\n",
    "\n",
    "    def __init__(self, inputs, targets):\n",
    "        \"\"\" Constructor - setups dimensions and initializes weights\"\"\"\n",
    "        # Set up network size\n",
    "        if np.ndim(inputs) > 1:\n",
    "            self.nIn = np.shape(inputs)[1]\n",
    "        else:\n",
    "            self.nIn = 1\n",
    "\n",
    "        if np.ndim(targets) > 1:\n",
    "            self.nOut = np.shape(targets)[1]\n",
    "        else:\n",
    "            self.nOut = 1\n",
    "\n",
    "        self.nData = np.shape(inputs)[0]\n",
    "\n",
    "        # Initialise network weights - random guess\n",
    "        self.weights = np.random.rand(self.nIn + 1, self.nOut) * 0.1 - 0.05\n",
    "\n",
    "        \n",
    "    # Use this to predict target for a given feature vector 'point'\n",
    "    def predict(self, point):\n",
    "        input_with_bias = np.concatenate((point, -np.ones((1, 1))), axis=1)\n",
    "        activations = self.forward(input_with_bias)\n",
    "        print(\"Prediction for input {} is {}:\".format(point, activations))\n",
    "\n",
    "        \n",
    "    # Train network\n",
    "    def train(self, inputs, targets, eta, nIterations):\n",
    "        \"\"\" Train the thing \"\"\"\n",
    "        # Add one bias node\n",
    "        inputs = np.concatenate((inputs, -np.ones((self.nData, 1))), axis=1)\n",
    "\n",
    "        # Training: activation function - sign       \n",
    "        activations = self.forward(inputs)\n",
    "        for n in range(nIterations):\n",
    "            print(\"Iteration: \", n+1)\n",
    "            print(\"Current weights:\", self.weights.tolist())\n",
    "\n",
    "            print(\"Current activations:\",  activations.tolist())\n",
    "            print(\"Targets:\", targets.tolist())\n",
    "            \n",
    "            # need to take an absolute value of difference - to aoid cancelling out\n",
    "            total_error = np.sum(abs(activations - targets))\n",
    "            print(\"Error:\", total_error)\n",
    "            if total_error == 0:\n",
    "                print()\n",
    "                break\n",
    "\n",
    "            print()\n",
    "            # update weights - each weight is updated separately            \n",
    "            self.weights -= eta * np.dot(np.transpose(inputs), activations - targets)\n",
    "            activations = self.forward(inputs)\n",
    "        \n",
    "        print(\"Final weights:\", self.weights.tolist())\n",
    "        print(\"Targets:\", targets.tolist())\n",
    "        print(\"Final predictions:\", activations.tolist())\n",
    "\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Run the network forward \"\"\"\n",
    "        # Compute activations\n",
    "        activations = np.dot(inputs, self.weights)\n",
    "\n",
    "        # Threshold the activations with sign function\n",
    "        return np.where(activations > 0, 1, 0)\n",
    "\n",
    "    def confusion_matrix(self, inputs, targets):\n",
    "        \"\"\"Confusion matrix\"\"\"\n",
    "\n",
    "        # Add the bias node\n",
    "        inputs = np.concatenate((inputs, -np.ones((self.nData, 1))), axis=1)\n",
    "\n",
    "        outputs = np.dot(inputs, self.weights)\n",
    "\n",
    "        nClasses = np.shape(targets)[1]\n",
    "\n",
    "        if nClasses == 1:\n",
    "            nClasses = 2\n",
    "            outputs = np.where(outputs > 0, 1, 0)\n",
    "        else:\n",
    "            # 1-of-N encoding\n",
    "            outputs = np.argmax(outputs, 1)\n",
    "            targets = np.argmax(targets, 1)\n",
    "\n",
    "        cm = np.zeros((nClasses, nClasses))\n",
    "        for i in range(nClasses):\n",
    "            for j in range(nClasses):\n",
    "                cm[i, j] = np.sum(np.where(outputs == i, 1, 0) * np.where(targets == j, 1, 0))\n",
    "\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "        print(\"Accuracy:\", np.trace(cm) / np.sum(cm))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Learning concept of OR\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_OR.png\" title=\"Decision boundary for OR\" width=\"400px\">\n",
    "    <figcaption>Fig 2. Perceptron can learn a decision boundary for OR data.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "\n",
    "# set up the size of the input vector and initial random weights\n",
    "p = Perceptron(a[:, 0:2], a[:, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction before learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "Prediction for input [[0 0]] is [[0]]:\n",
      "\n",
      "Prediction for input [[0.9 0. ]] is [[0]]:\n",
      "\n",
      "Prediction for input [[0.  0.8]] is [[1]]:\n"
     ]
    }
   ],
   "source": [
    "print(\"Before training:\")\n",
    "test = np.array([[0, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0.9, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0, 0.8]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now learns from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Current weights: [[-0.04662414475094431], [0.04577975898086402], [0.01732915930833126]]\n",
      "Current activations: [[0], [1], [0], [0]]\n",
      "Targets: [[0], [1], [1], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  2\n",
      "Current weights: [[0.05337585524905569], [0.09577975898086402], [-0.08267084069166875]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[0], [1], [1], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  3\n",
      "Current weights: [[0.05337585524905569], [0.09577975898086402], [-0.03267084069166874]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[0], [1], [1], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  4\n",
      "Current weights: [[0.05337585524905569], [0.09577975898086402], [0.01732915930833126]]\n",
      "Current activations: [[0], [1], [1], [1]]\n",
      "Targets: [[0], [1], [1], [1]]\n",
      "Error: 0\n",
      "\n",
      "Final weights: [[0.05337585524905569], [0.09577975898086402], [0.01732915930833126]]\n",
      "Targets: [[0], [1], [1], [1]]\n",
      "Final predictions: [[0], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "p.train(a[:, 0:2], a[:, 2:], 0.05, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[1. 0.]\n",
      " [0. 3.]]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "p.confusion_matrix(a[:, 0:2], a[:, 2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now can classify any input of OR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "Prediction for input [[0 0]] is [[0]]:\n",
      "\n",
      "Prediction for input [[0.9 0. ]] is [[1]]:\n",
      "\n",
      "Prediction for input [[0.  0.8]] is [[1]]:\n"
     ]
    }
   ],
   "source": [
    "print(\"After training:\")\n",
    "test = np.array([[0, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0.9, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0, 0.8]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Learning concept of AND\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_AND.png\" title=\"Decision boundary for AND\" width=\"400px\">\n",
    "    <figcaption>Fig 3. Perceptron can learn a decision boundary for AND data.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "Prediction for input [[0 0]] is [[1]]:\n",
      "\n",
      "Prediction for input [[0.8 0. ]] is [[1]]:\n",
      "\n",
      "Prediction for input [[0.  0.9]] is [[1]]:\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[0, 0, 0], [0, 1, 0], [1, 0, 0], [1, 1, 1]])\n",
    "\n",
    "# new perceptron: set up the size of the input vector and initial random weights\n",
    "p = Perceptron(a[:, 0:2], a[:, 2:])\n",
    "\n",
    "print(\"Before training:\")\n",
    "test = np.array([[0, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0.8, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0, 0.9]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Current weights: [[0.03133017968549076], [-0.004459860729580503], [-0.040396705223364554]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 3\n",
      "\n",
      "Iteration:  2\n",
      "Current weights: [[-0.01866982031450924], [-0.054459860729580506], [0.10960329477663547]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  3\n",
      "Current weights: [[0.03133017968549076], [-0.004459860729580503], [0.059603294776635465]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  4\n",
      "Current weights: [[0.08133017968549076], [0.0455401392704195], [0.009603294776635463]]\n",
      "Current activations: [[0], [1], [1], [1]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  5\n",
      "Current weights: [[0.03133017968549076], [-0.004459860729580503], [0.10960329477663547]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  6\n",
      "Current weights: [[0.08133017968549076], [0.0455401392704195], [0.059603294776635465]]\n",
      "Current activations: [[0], [0], [1], [1]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  7\n",
      "Current weights: [[0.03133017968549076], [0.0455401392704195], [0.10960329477663547]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  8\n",
      "Current weights: [[0.08133017968549076], [0.0955401392704195], [0.059603294776635465]]\n",
      "Current activations: [[0], [1], [1], [1]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  9\n",
      "Current weights: [[0.03133017968549076], [0.0455401392704195], [0.15960329477663548]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 1\n",
      "\n",
      "Iteration:  10\n",
      "Current weights: [[0.08133017968549076], [0.0955401392704195], [0.10960329477663548]]\n",
      "Current activations: [[0], [0], [0], [1]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Error: 0\n",
      "\n",
      "Final weights: [[0.08133017968549076], [0.0955401392704195], [0.10960329477663548]]\n",
      "Targets: [[0], [0], [0], [1]]\n",
      "Final predictions: [[0], [0], [0], [1]]\n"
     ]
    }
   ],
   "source": [
    "p.train(a[:, 0:2], a[:, 2:], 0.05, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[3. 0.]\n",
      " [0. 1.]]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "p.confusion_matrix(a[:, 0:2], a[:, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training:\n",
      "Prediction for input [[0 0]] is [[0]]:\n",
      "\n",
      "Prediction for input [[0.8 0. ]] is [[0]]:\n",
      "\n",
      "Prediction for input [[0.  0.9]] is [[0]]:\n"
     ]
    }
   ],
   "source": [
    "print(\"After training:\")\n",
    "\n",
    "test = np.array([[0, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0.8, 0]])\n",
    "p.predict(test)\n",
    "print()\n",
    "test = np.array([[0, 0.9]])\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Concept of exclusive OR (XOR)\n",
    "<figure align=\"middle\">\n",
    "    <img src=\"images/perceptron_XOR.png\" title=\"XOR is not linearly separable\" width=\"400px\">\n",
    "    <figcaption>Fig 4. Decision boundary for $x_1$ XOR $x_2$.</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training:\n",
      "Prediction for input [[0 0]] is [[0]]:\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0], [1, 1, 1]])\n",
    "\n",
    "# new perceptron: set up the size of the input vector and initial random weights\n",
    "p = Perceptron(a[:, 0:2], a[:, 2:])\n",
    "\n",
    "test = np.array([[0, 0]]) \n",
    "print(\"Before training:\")\n",
    "p.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1\n",
      "Current weights: [[0.021673173059180956], [0.04324579911162746], [0.028458060169640295]]\n",
      "Current activations: [[0], [1], [0], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  2\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  3\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  4\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  5\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  6\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  7\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  8\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  9\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  10\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  11\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  12\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  13\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  14\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  15\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  16\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  17\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  18\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  19\n",
      "Current weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Current activations: [[1], [1], [1], [1]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Iteration:  20\n",
      "Current weights: [[0.021673173059180956], [-0.006754200888372544], [0.028458060169640295]]\n",
      "Current activations: [[0], [0], [0], [0]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Error: 2\n",
      "\n",
      "Final weights: [[0.07167317305918096], [0.04324579911162746], [-0.07154193983035971]]\n",
      "Targets: [[1], [0], [0], [1]]\n",
      "Final predictions: [[1], [1], [1], [1]]\n"
     ]
    }
   ],
   "source": [
    "p.train(a[:, 0:2], a[:, 2:], 0.05, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptron cannot learn XOR: in 2 dimensions XOR vectors are not linearly-separable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2022 Marina Barsky. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
